{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tokenizers\n",
    "import transformers\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_strongly_connected(adj):\n",
    "    adj = adj.to(torch.int64)\n",
    "    reach = adj.clone()\n",
    "\n",
    "    prev = torch.zeros_like(reach)\n",
    "    while not torch.equal(prev, reach):\n",
    "        prev = reach.clone()\n",
    "        intermediate = ((reach @ reach)>0).to(dtype=torch.int64)#propagate\n",
    "        reach = reach | intermediate\n",
    "        \n",
    "    if not reach.all():\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def edge_mat_to_adj(edges):\n",
    "    n=edges.size(0)\n",
    "    # Create an n x n Boolean tensor initialized with False.\n",
    "    adj = torch.zeros(n, n, dtype=torch.bool)\n",
    "    \n",
    "    # Create a row index for each entry in the edge matrix.\n",
    "    # This will be an n x k matrix where each row i is filled with i.\n",
    "    row_indices = torch.arange(n).unsqueeze(1).expand_as(edges)\n",
    "\n",
    "    mask= edges != -1\n",
    "    \n",
    "    # Use advanced indexing to set the corresponding entries to True.\n",
    "    adj[row_indices[mask], edges[mask]] = True\n",
    "    \n",
    "    return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_ablate 5\n",
      "Total unique paths of length 1 to 10: 2547335\n"
     ]
    }
   ],
   "source": [
    "#hyper parameters\n",
    "n_nodes=5\n",
    "n_actions=5\n",
    "n_ablate=\"0.2\"\n",
    "seed=0\n",
    "#\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "n_edges=n_nodes*n_actions\n",
    "if type(n_ablate) == str:\n",
    "    n_ablate = int(float(n_ablate)*n_edges)\n",
    "print(\"n_ablate\", n_ablate)\n",
    "while True:\n",
    "    edge_mat=torch.randint(0,n_nodes,(n_nodes, n_actions),dtype=torch.int64)\n",
    "    adj=edge_mat_to_adj(edge_mat)\n",
    "    mask=torch.rand(n_nodes,n_actions)\n",
    "    sorted_mask=torch.argsort(mask.flatten())\n",
    "    i,j=torch.unravel_index(sorted_mask[:int(n_ablate)], mask.shape)\n",
    "    mask[i,j]=-1\n",
    "    mask=mask>=0\n",
    "    edge_mat_masked=edge_mat.clone()\n",
    "    edge_mat_masked[~mask]=-1\n",
    "    adj_masked=edge_mat_to_adj(edge_mat_masked)\n",
    "    if is_strongly_connected(adj) and is_strongly_connected(adj_masked):\n",
    "        assert edge_mat.any(1).all(), \"edge mat has no edges\"\n",
    "        assert edge_mat_masked.any(1).all(), \"masked edge mat has no edges\"\n",
    "        break\n",
    "\n",
    "def count_paths(adj, max_length=10):\n",
    "    # Convert the boolean adj matrix to int for multiplication\n",
    "    A = adj.to(torch.int64)\n",
    "    total_paths = 0\n",
    "    A_power = A.clone()\n",
    "    for L in range(1, max_length+1):\n",
    "        total_paths += A_power.sum().item()\n",
    "        A_power = torch.matmul(A_power, A)\n",
    "    return total_paths\n",
    "\n",
    "# Example usage:\n",
    "total = count_paths(adj, max_length=10)\n",
    "print(\"Total unique paths of length 1 to 10:\", total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 262144/262144 [00:28<00:00, 9354.11it/s]\n",
      "100%|██████████| 262144/262144 [00:28<00:00, 9150.86it/s]\n",
      "100%|██████████| 262144/262144 [00:29<00:00, 8860.60it/s]\n"
     ]
    }
   ],
   "source": [
    "#generate a problem\n",
    "n_problems=262144\n",
    "data={}\n",
    "edge_mat_full=edge_mat.clone()\n",
    "for key,edge_mat_used in zip([\"train\",\"test_rl\",\"test\"],[edge_mat_masked,edge_mat,edge_mat]):\n",
    "    edge_mat_used=edge_mat_used.clone()\n",
    "    i_starts=torch.randint(0,n_nodes,(n_problems,),dtype=torch.int64)\n",
    "    lengths=torch.randint(1,10,(n_problems,),dtype=torch.int64)\n",
    "    paths=[]\n",
    "    actionss=[]\n",
    "    prompts=[]\n",
    "    completions=[]\n",
    "    num_maskeds=[]\n",
    "    for i in tqdm.trange(n_problems):\n",
    "        i_curr=i_starts[i].item()\n",
    "        length=lengths[i]\n",
    "        path=[i_curr]\n",
    "        actions=[]\n",
    "        for j in range(length):\n",
    "            avail_actions=torch.where(edge_mat_used[i_curr]!= -1)[0]\n",
    "            #randomly select an action\n",
    "            i_action=torch.torch.randint(0,len(avail_actions),(1,),dtype=torch.int64)\n",
    "            i_action=avail_actions[i_action].item()\n",
    "            #take the action\n",
    "            i_next=edge_mat_used[i_curr,i_action].item()\n",
    "            path.append(i_next)\n",
    "            actions.append(i_action)\n",
    "            i_curr=i_next\n",
    "        action_dests=edge_mat_masked[torch.tensor(path[:-1]),torch.tensor(actions)]\n",
    "        num_masked=torch.sum(action_dests == -1)\n",
    "        #print(key, \"num masked:\", num_masked.item())\n",
    "        assert len(path) == length+1 and len(actions) == length, \"path and actions have different lengths\"\n",
    "        paths.append(path)\n",
    "        actionss.append(actions)\n",
    "        prompt=\"S\"+str(path[0])+\" \"\n",
    "        prompt+=\"\".join([\"a\"+str(i)+\" \" for i in actions])\n",
    "        prompt+=\": \"#find\n",
    "        completion=\"\".join([\"S\"+str(i)+\" \" for i in path])\n",
    "        prompts.append(prompt)\n",
    "        completions.append(completion)\n",
    "        num_maskeds.append(num_masked.item())\n",
    "        #break\n",
    "    data[key] = {\n",
    "        'paths': paths,\n",
    "        'actionss': actionss,\n",
    "        'prompts': prompts,\n",
    "        'completions': completions,\n",
    "        'num_maskeds': num_maskeds,\n",
    "        'edge_mat': edge_mat_used.tolist(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(data, f\"./data/raw_data/data-nn_{n_nodes}-na_{n_actions}-nab_{n_ablate}-seed_{seed}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompts', 'completions', 'num_maskeds', 'texts'],\n",
       "        num_rows: 262144\n",
       "    })\n",
       "    test_rl: Dataset({\n",
       "        features: ['prompts', 'completions', 'num_maskeds', 'texts'],\n",
       "        num_rows: 262144\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['prompts', 'completions', 'num_maskeds', 'texts'],\n",
       "        num_rows: 262144\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=torch.load(f\"./data/raw_data/data-nn_{n_nodes}-na_{n_actions}-nab_{n_ablate}-seed_{seed}.pt\",weights_only=False)\n",
    "dataset_data={}\n",
    "for key in data.keys():\n",
    "    prompts=data[key]['prompts']\n",
    "    completions=data[key]['completions']\n",
    "    num_maskeds=data[key]['num_maskeds']\n",
    "    texts=[p+c for p,c in zip(prompts,completions)]\n",
    "    data_={\n",
    "        \"prompts\": prompts,\n",
    "        \"completions\": completions,\n",
    "        \"num_maskeds\": num_maskeds,\n",
    "        'texts': texts,\n",
    "    }\n",
    "    dataset_data[key]=datasets.Dataset.from_dict(data_)\n",
    "dataset=datasets.DatasetDict(dataset_data)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name=f\"cfpark00/toy-multistep-nn_{n_nodes}-na_{n_actions}-nab_{n_ablate}-seed_{seed}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb1c04738bfe4b16922203710f8f0445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "529c3fe5b74b497fa9ff79b7c264e7c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/263 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e1680a5f3b241dfa0d4e5cc1c07aa6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3d9b69dc24747638cd14f7ef3e0818a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/263 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8560b953581a491bb3fe30e127284ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d319d1d7464245b6530944c6ba781c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/263 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/cfpark00/toy-multistep-nn_5-na_5-nab_5-seed_0/commit/b281b7758d7dc79e23498c9d3f52d072eb06eeee', commit_message='Upload dataset', commit_description='', oid='b281b7758d7dc79e23498c9d3f52d072eb06eeee', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/cfpark00/toy-multistep-nn_5-na_5-nab_5-seed_0', endpoint='https://huggingface.co', repo_type='dataset', repo_id='cfpark00/toy-multistep-nn_5-na_5-nab_5-seed_0'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.push_to_hub(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "import transformers\n",
    "from transformers import Qwen2Config\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sft_fol ./data/sft/toy-multistep-nn_10-na_10-nab_20-seed_0/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_10-na_20-nab_60-seed_1/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_20-na_20-nab_120-seed_1/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_10-na_5-nab_15-seed_1/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_10-na_5-nab_15-seed_2/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_20-na_10-nab_60-seed_0/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_5-na_5-nab_2-seed_2/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_20-na_20-nab_40-seed_1/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_5-na_5-nab_2-seed_1/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_10-na_10-nab_20-seed_1/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_20-na_20-nab_80-seed_2/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_20-na_20-nab_80-seed_1/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_20-na_10-nab_40-seed_0/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_5-na_20-nab_20-seed_2/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_10-na_5-nab_10-seed_0/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_5-na_5-nab_7-seed_0/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_5-na_5-nab_5-seed_2/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_10-na_5-nab_10-seed_1/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_10-na_5-nab_5-seed_2/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_5-na_20-nab_10-seed_1/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_10-na_5-nab_5-seed_1/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_20-na_20-nab_40-seed_0/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_5-na_20-nab_30-seed_1/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_5-na_10-nab_5-seed_1/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_10-na_20-nab_60-seed_2/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_5-na_10-nab_15-seed_2/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_10-na_20-nab_40-seed_1/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_10-na_20-nab_60-seed_0/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_5-na_5-nab_5-seed_1/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_20-na_5-nab_10-seed_2/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_20-na_5-nab_30-seed_2/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_20-na_10-nab_20-seed_1/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_5-na_20-nab_20-seed_1/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_5-na_10-nab_15-seed_0/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_5-na_5-nab_5-seed_0/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_20-na_10-nab_20-seed_0/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_5-na_10-nab_10-seed_1/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_5-na_10-nab_5-seed_0/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_20-na_10-nab_40-seed_2/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_10-na_20-nab_20-seed_2/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_5-na_20-nab_10-seed_2/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_5-na_10-nab_10-seed_2/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_10-na_10-nab_20-seed_2/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_10-na_10-nab_30-seed_0/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_5-na_20-nab_20-seed_0/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_5-na_5-nab_7-seed_2/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_10-na_10-nab_10-seed_1/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_20-na_5-nab_20-seed_1/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_5-na_20-nab_10-seed_0/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_10-na_10-nab_10-seed_2/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_5-na_10-nab_15-seed_1/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_20-na_5-nab_10-seed_1/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_20-na_5-nab_30-seed_1/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_20-na_10-nab_20-seed_2/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_10-na_20-nab_40-seed_2/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_20-na_20-nab_80-seed_0/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_10-na_20-nab_20-seed_1/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_10-na_10-nab_30-seed_1/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_5-na_20-nab_30-seed_0/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_20-na_20-nab_120-seed_0/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_5-na_5-nab_2-seed_0/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_20-na_10-nab_40-seed_1/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_5-na_20-nab_30-seed_2/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_10-na_5-nab_5-seed_0/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_20-na_20-nab_40-seed_2/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_20-na_5-nab_10-seed_0/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_20-na_20-nab_120-seed_2/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_5-na_10-nab_5-seed_2/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_20-na_10-nab_60-seed_1/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_10-na_10-nab_10-seed_0/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_20-na_5-nab_20-seed_0/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_10-na_5-nab_10-seed_2/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_20-na_10-nab_60-seed_2/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_20-na_5-nab_20-seed_2/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_10-na_5-nab_15-seed_0/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_10-na_20-nab_20-seed_0/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_20-na_5-nab_30-seed_0/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_10-na_10-nab_30-seed_2/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_5-na_5-nab_7-seed_1/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_5-na_10-nab_10-seed_0/final_model\n",
      "sft_fol ./data/sft/toy-multistep-nn_10-na_20-nab_40-seed_0/final_model\n"
     ]
    }
   ],
   "source": [
    "for sft_fol in glob.glob(\"./data/sft/*/final_model\"):\n",
    "    print(\"sft_fol\", sft_fol)\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(sft_fol)\n",
    "    tokenizer.eos_token = tokenizer.pad_token\n",
    "    tokenizer.eos_token_id = tokenizer.pad_token_id\n",
    "    tokenizer.save_pretrained(sft_fol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sft_fol ./data/sft/toy-multistep-nn_10-na_10-nab_20-seed_0/final_model\n"
     ]
    }
   ],
   "source": [
    "for sft_fol in glob.glob(\"./data/sft/*/final_model\"):\n",
    "    print(\"sft_fol\", sft_fol)\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(sft_fol)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #hyper parameters\n",
    "    argss=[]\n",
    "    for n_nodes in [5,10,20]:\n",
    "        for n_actions in [5,10,20]:\n",
    "            argss.append({\n",
    "                \"n_nodes\":n_nodes,\n",
    "                \"n_actions\":n_actions\n",
    "            })\n",
    "\n",
    "    for args in argss:\n",
    "        n_nodes=args[\"n_nodes\"]\n",
    "        n_actions=args[\"n_actions\"]\n",
    "        #\n",
    "        i_curr=0\n",
    "        vocab = {\n",
    "            \"<unk>\": i_curr,\n",
    "            \"<bos>\": i_curr+1,\n",
    "            \"<pad>\": i_curr + 2,\n",
    "            \":\": i_curr + 3,\n",
    "        }\n",
    "        i_curr += len(vocab)\n",
    "        for i in range(n_nodes):\n",
    "            vocab[f\"S{i}\"] = i_curr\n",
    "            i_curr += 1\n",
    "        for i in range(n_actions):\n",
    "            vocab[f\"a{i}\"] = i_curr\n",
    "            i_curr += 1\n",
    "\n",
    "        model_name=f\"cfpark00/toy-multistep-nn_{n_nodes}-na_{n_actions}\"\n",
    "\n",
    "        model = WordLevel(vocab=vocab, unk_token=\"<unk>\")\n",
    "        tokenizer = Tokenizer(model)\n",
    "        tokenizer.pre_tokenizer = Whitespace()\n",
    "        tokenizer = PreTrainedTokenizerFast(tokenizer_object=tokenizer,pad_token=\"<pad>\",eos_token=\"<pad>\")\n",
    "        tokenizer.push_to_hub(model_name)\n",
    "\n",
    "        model_config=Qwen2Config(\n",
    "            hidden_size=512,\n",
    "            intermediate_size=2048,\n",
    "            num_hidden_layers=4,\n",
    "            num_attention_heads=4,\n",
    "            num_key_value_heads=4,\n",
    "            vocab_size=len(tokenizer.vocab),\n",
    "        )\n",
    "        model=transformers.AutoModelForCausalLM.from_config(model_config)\n",
    "        model.push_to_hub(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "verl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
